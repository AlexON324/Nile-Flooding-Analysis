import numpy as np
import pandas as pd
import scipy.stats

class LocalLevelModel:
    def __init__(self, a1, P1, sigE, sigN, calculateConfidenceBounds=False, confidenceLevel=np.nan):
         self.a1 = a1
         self.P1 = P1
         self.sigE = sigE
         self.sigN = sigN
         self.calculateConfidenceBounds = calculateConfidenceBounds
         self.confidenceLevel = confidenceLevel

    def CalculateIntermediates(self, y):
        kalmanFilterResults = self.CalculateKalmanFilterResults(y)
        allResults = y.join(kalmanFilterResults)

        smoothedStateVarianceResults = self._CalculateSmoothedStateVariance(allResults)
        allResults = allResults.join(smoothedStateVarianceResults)

        disturbanceSmoothingResults = self._CalculateDisturbanceSmoothing(allResults)
        allResults = allResults.join(disturbanceSmoothingResults)

        utStarRtStartResults = self._CalculateUtStarRtStar(allResults)
        allResults = allResults.join(utStarRtStartResults)

        errorVectorResults = self._CalculateErrorVectors(allResults)
        allResults = allResults.join(errorVectorResults)

        return allResults

    def CalculateKalmanFilterResults(self, yDf):
        y = yDf.to_numpy()

        n = len(y)
        results = np.empty((n, 8))
        
        at = self.a1
        Pt = self.P1
        atUpperBound = np.nan
        atLowerBound = np.nan
        for t in range(n):
            yt = y[t]
            
            Ft = Pt + self.sigE

            if np.isnan(yt):
                vt = 0
                Kt = 0
            else:
                vt = yt - at
                Kt = Pt / Ft
                
            att = at + Kt * vt

            if self.calculateConfidenceBounds:
                confidence = self.__mean_confidence_interval(at,Pt,self.confidenceLevel)
                atUpperBound = confidence[1]
                atLowerBound = confidence[0]

            #add to results
            results[t,:] = [at,Pt,vt,Ft,Kt,att,atUpperBound,atLowerBound]
            
            #Get next at, Pt
            at = at + Kt * vt
            Pt = Pt * (1 - Kt) + self.sigN


        
        resultsDf = pd.DataFrame(results, columns=["a","P","v","F","K","at","aUpperBound","aLowerBound"])
        resultsDf.index = yDf.index

        if not self.calculateConfidenceBounds:
            resultsDf = resultsDf.drop(["aUpperBound","aLowerBound"], axis = 1)

        return resultsDf

    def _CalculateSmoothedStateVariance(self, resultsFromPreviousSteps):
        n = resultsFromPreviousSteps.shape[0]
        results = np.empty((n, 6))

        #initialisation
        rt_1 = 0
        Nt_1 = 0
        results[-1,0] = rt_1
        results[-1,2] = Nt_1
        alphaHattUpperBound = np.nan
        alphaHattLowerBound = np.nan
        for t in range(n-1, -1, -1):
            index = resultsFromPreviousSteps.index[t]
            vt = resultsFromPreviousSteps.loc[index,"v"]
            Ft = resultsFromPreviousSteps.loc[index,"F"]
            Kt = resultsFromPreviousSteps.loc[index,"K"]
            at = resultsFromPreviousSteps.loc[index,"a"]
            Pt = resultsFromPreviousSteps.loc[index,"P"]
            yt = resultsFromPreviousSteps.loc[index,"y"]

            Lt = 1 - Kt  
            rt_1 = (vt / Ft) + (Lt * rt_1)
            alphaHatt = at + (Pt * rt_1)

            if not np.isnan(yt):
                Nt_1 = (1 / Ft) + ((Lt**2) * Nt_1)
            Vt = Pt - ((Pt**2) * Nt_1)

            if self.calculateConfidenceBounds:
                confidence = self.__mean_confidence_interval(alphaHatt,Vt,self.confidenceLevel)
                alphaHattUpperBound = confidence[1]
                alphaHattLowerBound = confidence[0]

            #add to results
            results[t,1] = alphaHatt
            results[t,3] = Vt
            results[t,4] = alphaHattUpperBound
            results[t,5] = alphaHattLowerBound
            if t-1 >=0:
                results[t-1,0] = rt_1
                results[t-1,2] = Nt_1

        resultsDf = pd.DataFrame(results, columns=["r","alphaHat","N","V","alphaHatUpperBound","alphaHatLowerBound"])    
        resultsDf.index = resultsFromPreviousSteps.index

        if not self.calculateConfidenceBounds:
            resultsDf = resultsDf.drop(["alphaHatUpperBound","alphaHatLowerBound"], axis = 1)

        return resultsDf

    def _CalculateDisturbanceSmoothing(self, resultsFromPreviousSteps): 
        n = resultsFromPreviousSteps.shape[0]
        results = np.empty((n, 8))

        for t in range(n-1, -1, -1):
            index = resultsFromPreviousSteps.index[t]
            Ft = resultsFromPreviousSteps.loc[index,"F"]
            vt = resultsFromPreviousSteps.loc[index,"v"]
            Kt = resultsFromPreviousSteps.loc[index,"K"]
            rt = resultsFromPreviousSteps.loc[index,"r"]
            Nt = resultsFromPreviousSteps.loc[index,"N"]

            ut = (vt / Ft) - (Kt * rt)
            etHat = self.sigE * ut
            Dt = (Ft ** -1) + ((Kt ** 2) * Nt)
            VaretYn = self.sigE - ((self.sigE ** 2) * Dt) 
            ntHat = self.sigN * rt
            VarntYn = self.sigN - ((self.sigN ** 2) * Nt)
            
            VaretYnStdDev = np.sqrt(VaretYn)
            VarntYnStdDev = np.sqrt(VarntYn)

            results[t,:] = [ut, etHat, Dt, VaretYn, ntHat, VarntYn, VaretYnStdDev, VarntYnStdDev]

        resultsDf = pd.DataFrame(results, columns=["u","eHat","D","VareY","nHat","VarnY", "VareYStdDev", "VarnYStdDev"])
        resultsDf.index = resultsFromPreviousSteps.index
        return resultsDf

    def _CalculateUtStarRtStar(self, resultsFromPreviousSteps):
        n = resultsFromPreviousSteps.shape[0]
        results = np.empty((n, 2))

        for t in range(n):
            index = resultsFromPreviousSteps.index[t]
            Nt = resultsFromPreviousSteps.loc[index,"N"]
            ut = resultsFromPreviousSteps.loc[index,"u"]
            Dt = resultsFromPreviousSteps.loc[index,"D"]
            rt = resultsFromPreviousSteps.loc[index,"r"]

            utStar = (Dt**(-1/2))*ut
            rtStar = (Nt**(-1/2))*rt 

            results[t,:] = [utStar, rtStar]

        resultsDf = pd.DataFrame(results, columns=["uStar","rStar"])
        resultsDf.index = resultsFromPreviousSteps.index
        return resultsDf

    def _CalculateErrorVectors(self, resultsFromPreviousSteps):
        n = resultsFromPreviousSteps.shape[0]
        et = np.zeros(n)

        for t in range(n):
            index = resultsFromPreviousSteps.index[t]
            vt = resultsFromPreviousSteps.loc[index,"v"]
            Ft = resultsFromPreviousSteps.loc[index,"F"]

            et[t] = vt / np.sqrt(Ft)

        resultsDf = pd.DataFrame(et, columns=["e"])
        resultsDf.index = resultsFromPreviousSteps.index
        return resultsDf

    def __mean_confidence_interval(self,mean, variance, confidence):
        return scipy.stats.norm.interval(confidence, loc=mean, scale=np.sqrt(variance))
